{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jog_forward: train set : 1919 \t| testset: 100\n",
      "jog_turn: train set : 887 \t| testset: 100\n",
      "walk_forward: train set : 2877 \t| testset: 100\n",
      "walk_turn: train set : 936 \t| testset: 100\n",
      "run_forward: train set : 929 \t| testset: 100\n",
      "stationary: train set : 396 \t| testset: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "from utils import *\n",
    "from model import CNN_m123 as CNN\n",
    "from train_harcnn import *\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "plt.rcParams['figure.figsize'] = [30, 30]\n",
    "np.random.seed(42)\n",
    "\n",
    "LABEL = {'jog_forward': 0, 'jog_turn': 1, 'walk_forward': 2, 'walk_turn': 3, 'run_forward':4, 'stationary':5}\n",
    "LABEL_INV = {0:'jog_forward', 1:'jog_turn', 2:'walk_forward', 3:'walk_turn', 4:'run_forward', 5:'stationary'}\n",
    "\n",
    "n_sample = 100\n",
    "\n",
    "# Possible Sampling Rates\n",
    "#SR_GNSS = [1,2,3,4,5,6,7,8,9,10]\n",
    "SR_GNSS = [1,2,4,10]\n",
    "SR_IMU = [10,20,25,50,100]\n",
    "\n",
    "# Sampling rate for each movement category in Hz\n",
    "SR = {  \n",
    "    LABEL['walk_forward']: [2,100],\n",
    "    LABEL['walk_turn']: [2,100],\n",
    "    LABEL['jog_forward']: [2,100],\n",
    "    LABEL['jog_turn']: [2,100],\n",
    "    LABEL['run_forward']: [2,100],\n",
    "    LABEL['stationary']: [2,100],\n",
    "}\n",
    "# Power Consumption ([mA]*[V])\n",
    "PW_GNSS = {\n",
    "    0: 23,\n",
    "    1: 35,\n",
    "    2: 40,\n",
    "    3: 44,\n",
    "    4: 48,\n",
    "    5: 50,\n",
    "    6: 53,\n",
    "    7: 57,\n",
    "    8: 60,\n",
    "    9: 63,\n",
    "    10:65\n",
    "    }\n",
    "\n",
    "PW_IMU = {\n",
    "    0:10,\n",
    "    10:11,\n",
    "    20:12,\n",
    "    25:15,\n",
    "    33:18,\n",
    "    50:22,\n",
    "    100:24,\n",
    "}\n",
    "dir_data = Path('./data/datasets_fin/')\n",
    "\n",
    "images = np.load(dir_data/'train_images.npy')\n",
    "labels = np.load(dir_data/'train_labels.npy')\n",
    "gnss = np.load(dir_data/'train_gnss.npy')\n",
    "images = images[np.newaxis, ...].reshape(-1,1,16,100)\n",
    "\n",
    "train_images = {key: [] for key in LABEL}\n",
    "train_gnss = {key: [] for key in LABEL}\n",
    "for i in range(len(labels)):\n",
    "    label = LABEL_INV[labels[i][0]]\n",
    "    train_images[label].append(images[i])\n",
    "    train_gnss[label].append(gnss[i])\n",
    "    \n",
    "    \n",
    "\n",
    "images = np.load(dir_data/'test_images.npy')\n",
    "labels = np.load(dir_data/'test_labels.npy')\n",
    "gnss = np.load(dir_data/'test_gnss.npy')\n",
    "images = images[np.newaxis, ...].reshape(-1,1,16,100)\n",
    "\n",
    "test_images = {key: [] for key in LABEL}\n",
    "test_gnss = {key: [] for key in LABEL}\n",
    "for i in range(len(labels)):\n",
    "    label = LABEL_INV[labels[i][0]]\n",
    "    test_images[label].append(images[i])\n",
    "    test_gnss[label].append(gnss[i])\n",
    "    \n",
    "for label in LABEL:\n",
    "    print(f\"{label}: train set : {len(train_images[label])} \\t| testset: {len(test_images[label])}\")\n",
    "\n",
    "\n",
    "net = CNN(n_classes=6)\n",
    "net.load_state_dict(torch.load(Path('./models/MyModel.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "def get_key(val, my_dict):\n",
    "    return [keys for keys, values in my_dict.items() if val==values][0]\n",
    "\n",
    "\n",
    "def show_gps_label(df, idx_start=0, idx_end=None, enu_format=True, annotate=False, markersize=10):\n",
    "    time = df[['time']][idx_start:idx_end].to_numpy()\n",
    "    lat  = df[['latitude']][idx_start:idx_end].to_numpy()\n",
    "    lon  = df[['longitude']][idx_start:idx_end].to_numpy()\n",
    "    enu_x = df[['enu_x']][idx_start:idx_end].to_numpy()\n",
    "    enu_y = df[['enu_y']][idx_start:idx_end].to_numpy()\n",
    "    label = df[['prediction']][idx_start:idx_end].to_numpy()\n",
    "    \n",
    "    pos_range = [129.3186, 129.3202, 36.0124, 36.0140] # POSTECH Field\n",
    "\n",
    "    if(enu_format):\n",
    "        lat = enu_y\n",
    "        lon = enu_x\n",
    "    else:\n",
    "        #plt.axis(pos_range)\n",
    "        img = plt.imread(\"background2.png\")\n",
    "        plt.imshow(img, extent=pos_range)\n",
    "    print(\"DATAFRAME LENGTH: \",len(df))\n",
    "    \n",
    "    color = {'walk_forward': 'tab:green',\n",
    "             'walk_turn': 'tab:blue',\n",
    "             'jog_forward': 'tab:orange',\n",
    "             'jog_turn': 'tab:purple',\n",
    "             'run_forward': 'tab:red',\n",
    "             'stationary': 'tab:magenta',\n",
    "            }\n",
    "    plt.title(color,fontsize=30)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        p = get_key(label[i])\n",
    "        if p in LABEL:\n",
    "            c = color[p]\n",
    "        else:\n",
    "            c = 'k'\n",
    "        plt.plot(lon[i], lat[i], marker='o', color = c, markersize=markersize)\n",
    "        \n",
    "    if(annotate):\n",
    "        for idx, xy in enumerate(zip(lon,lat)):\n",
    "                if(idx % 10 == 0):\n",
    "                    plt.annotate('{}'.format(df.index[idx]), xy=xy, textcoords='data', fontsize=20)\n",
    "                    \n",
    "def har_predict(images, sr_imu):\n",
    "    images = np.array(images)\n",
    "    with torch.no_grad():\n",
    "        if(sr_imu != n_sample):\n",
    "            images = downsample_imu(images, n_sample, sr_imu)\n",
    "            images = interpolate_imu(images, sr_imu, n_sample)\n",
    "        images = torch.Tensor(images)\n",
    "        images.requires_grad = False\n",
    "        net.eval()\n",
    "        res = net(images)\n",
    "        predictions = np.argmax(res.cpu().detach().numpy(), axis=-1)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def downsample_imu(images, from_f, to_f):\n",
    "    interval = int(from_f/to_f)\n",
    "    assert interval == float(from_f)/to_f, \"The sampling rate ratio must be a integer\"\n",
    "    return images[:,:,:,::interval]\n",
    "\n",
    "\n",
    "def interpolate_imu(a, from_f, to_f):\n",
    "    interval = int(to_f/from_f)\n",
    "    assert interval == float(to_f)/from_f, \"The sampling rate ratio must be a integer\"\n",
    "    arr = np.zeros([a.shape[0], a.shape[1], a.shape[2], a.shape[3]*interval], dtype=a.dtype)\n",
    "    arr[:,:,:,::interval] = a\n",
    "    inc = np.zeros(a.shape)\n",
    "    inc[:,:,:,:-1] = (a[:,:,:,1:] - a[:,:,:,:-1])/interval\n",
    "    inc[:,:,:,-1] = inc[:,:,:,-2]\n",
    "    for i in range(1,interval):\n",
    "        arr[:,:,:,i::interval] = arr[:,:,:,::interval] + inc*i\n",
    "    return arr\n",
    "\n",
    "def get_accuracy(pred, label, confusion_matrix):\n",
    "    correct = (pred == label).sum()\n",
    "    for i in LABEL.values():\n",
    "        confusion_matrix[label, i] = (pred == i).sum()\n",
    "    return correct/len(pred)\n",
    "\n",
    "\n",
    "def downsample(gnss_base, pred):\n",
    "    n_samples = 100\n",
    "    gnss_downsample = np.array(gnss_base).copy()\n",
    "    \n",
    "    gnss_cols = ['time','enu_x','enu_y','speed']\n",
    "    \n",
    "    f = lambda x: 10/SR[x][0]\n",
    "    sample_interval = np.fromiter([f(x) for x in pred], dtype=float)\n",
    "    \n",
    "    for i, sample in enumerate(gnss_downsample):\n",
    "        sample_points = np.floor(np.arange(10)*sample_interval[i]+0.5)\n",
    "        sample_points = np.append(sample_points[sample_points<10], 10)\n",
    "        drop_points = [x for x in np.arange(10) if x not in sample_points]\n",
    "        sample[:, drop_points] = np.nan\n",
    "    return gnss_downsample\n",
    "\n",
    "\n",
    "def interpolate(gnss_downsample):\n",
    "    gnss_interpolate = gnss_downsample[:,:-1,:-1].copy()\n",
    "    gnss_cols = ['time','enu_x','enu_y','speed']\n",
    "    for i, sample in enumerate(gnss_downsample):\n",
    "        df = pd.DataFrame(sample[:-1].T, columns=gnss_cols)\n",
    "        df = df.interpolate(method='polynomial', order=1, limit_direction='both')[:-1] # remove 11'th entry\n",
    "        gnss_interpolate[i] = df.to_numpy().T\n",
    "    return gnss_interpolate\n",
    "\n",
    "\n",
    "def calc_error(gnss_true, gnss_interpolate):\n",
    "    cols = ['time','enu_x','enu_y','speed']\n",
    "    \n",
    "    gnss_true = np.array(gnss_true)[:, :-1, :-1]\n",
    "    \n",
    "    x_org = gnss_true[cols.index('enu_x')]\n",
    "    y_org = gnss_true[cols.index('enu_y')]\n",
    "    x_est = gnss_interpolate[cols.index('enu_x')]\n",
    "    y_est = gnss_interpolate[cols.index('enu_y')]\n",
    "    \n",
    "    dist_org = np.sqrt(np.square(x_org[1:]-x_org[:-1])+np.square(y_org[1:]-y_org[:-1]))\n",
    "    dist_est = np.sqrt(np.square(x_est[1:]-x_est[:-1])+np.square(y_est[1:]-y_est[:-1]))\n",
    "    \n",
    "    dRMSE = np.sqrt(np.mean(np.square(dist_org-dist_est)))\n",
    "    pRMSE = np.sqrt(np.mean(np.square(x_org-x_est)+np.square(y_org-y_est)))\n",
    "    vRMSE = np.sqrt(np.mean(np.square(gnss_true[cols.index('speed')]-gnss_interpolate[cols.index('speed')])))\n",
    "    \n",
    "    return dRMSE, pRMSE, vRMSE\n",
    "\n",
    "\n",
    "def calc_power(predictions):\n",
    "    energy_consumption = {key: 0 for key in LABEL}\n",
    "    motion_count = {key: 0 for key in LABEL}\n",
    "    \n",
    "    for label in LABEL.keys():\n",
    "        motion_count[label] = (predictions == LABEL[label]).sum()\n",
    "        \n",
    "    for label in LABEL:\n",
    "        energy_consumption[label] = motion_count[label] * PW_GNSS[SR[LABEL[label]][0]] * 0.1 * 0.001# Joule per second\n",
    "        energy_consumption[label] += motion_count[label] * PW_IMU[SR[LABEL[label]][1]] * 0.1 * 0.001\n",
    "        \n",
    "    return np.mean(list(energy_consumption.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jog_forward 100 1.0\n",
      "jog_turn 100 0.98\n",
      "walk_forward 100 1.0\n",
      "walk_turn 100 1.0\n",
      "run_forward 100 1.0\n",
      "stationary 100 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[100,   0,   0,   0,   0,   0],\n",
       "       [  0,  98,   0,   0,   2,   0],\n",
       "       [  0,   0, 100,   0,   0,   0],\n",
       "       [  0,   0,   0, 100,   0,   0],\n",
       "       [  0,   0,   0,   0, 100,   0],\n",
       "       [  0,   0,   1,   0,   0,  99]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HAR Classification Test\n",
    "\n",
    "confusion_matrix = np.zeros([6,6], dtype=int)\n",
    "\n",
    "for i, label in enumerate(LABEL):\n",
    "    images = test_images[label]\n",
    "    gnss = test_gnss[label]\n",
    "    for key in SR.keys():\n",
    "        SR[key][1] = SR_IMU_PRE[key]\n",
    "    predictions = har_predict(images, SR[LABEL[label]][1])\n",
    "    har_acc[i] = get_accuracy(predictions, LABEL[label], confusion_matrix)\n",
    "    print(label, SR[LABEL[label]][1], har_acc[i])\n",
    "    \n",
    "        \n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jog_forward 100 1.0\n",
      "jog_turn 100 0.992108229988726\n",
      "walk_forward 100 0.9954814042405283\n",
      "walk_turn 100 0.9925213675213675\n",
      "run_forward 100 0.9989235737351991\n",
      "stationary 100 0.9848484848484849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1919,    0,    0,    0,    0,    0],\n",
       "       [   0,  880,    0,    0,    7,    0],\n",
       "       [   5,    0, 2864,    7,    1,    0],\n",
       "       [   0,    0,    7,  929,    0,    0],\n",
       "       [   1,    0,    0,    0,  928,    0],\n",
       "       [   0,    0,    4,    2,    0,  390]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Step; GNSS\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "SR_IMU_PRE = {  \n",
    "    LABEL['walk_forward']: 100,\n",
    "    LABEL['walk_turn']: 100,\n",
    "    LABEL['jog_forward']: 100,\n",
    "    LABEL['jog_turn']: 100,\n",
    "    LABEL['run_forward']: 100,\n",
    "    LABEL['stationary']: 100,\n",
    "}\n",
    "\n",
    "dfs_out = {key: [] for key in LABEL}\n",
    "confusion_matrix = np.zeros([6,6], dtype=int)\n",
    "\n",
    "# Calculate power, vRMSE, dRMSE\n",
    "har_acc = np.zeros(len(LABEL))\n",
    "power = np.zeros([len(LABEL), len(SR_GNSS)])\n",
    "vRMSE = np.zeros([len(LABEL), len(SR_GNSS)])\n",
    "dRMSE = np.zeros([len(LABEL), len(SR_GNSS)])\n",
    "pRMSE = np.zeros([len(LABEL), len(SR_GNSS)])\n",
    "\n",
    "for i, label in enumerate(LABEL):\n",
    "    images = train_images[label]\n",
    "    gnss = train_gnss[label]\n",
    "    for key in SR.keys():\n",
    "        SR[key][1] = SR_IMU_PRE[key]\n",
    "    predictions = har_predict(images, SR[LABEL[label]][1])\n",
    "    har_acc[i] = get_accuracy(predictions, LABEL[label], confusion_matrix)\n",
    "    print(label, SR[LABEL[label]][0], har_acc[i])\n",
    "    \n",
    "    for j, sr_gnss in enumerate(SR_GNSS):\n",
    "        for key in SR.keys():\n",
    "            SR[key][0] = sr_gnss\n",
    "        gnss_downsample = downsample(gnss, predictions)\n",
    "        gnss_interpolate = interpolate(gnss_downsample)\n",
    "        #print(sr_gnss, pd.DataFrame(gnss_interpolate[0].T,columns =  ['time','enu_x','enu_y','speed']))\n",
    "        power[i,j] = np.mean(calc_power(predictions))\n",
    "        dRMSE[i,j], pRMSE[i,j], vRMSE[i,j] = calc_error(gnss, gnss_interpolate)\n",
    "        \n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jog_forward 10 0.9911412193850964\n",
      "jog_forward 20 1.0\n",
      "jog_forward 25 1.0\n",
      "jog_forward 50 1.0\n",
      "jog_forward 100 1.0\n",
      "jog_turn 10 0.705749718151071\n",
      "jog_turn 20 0.895152198421646\n",
      "jog_turn 25 0.9560315670800451\n",
      "jog_turn 50 0.9763246899661782\n",
      "jog_turn 100 0.992108229988726\n",
      "walk_forward 10 0.9690649982620786\n",
      "walk_forward 20 0.9937434827945777\n",
      "walk_forward 25 0.9954814042405283\n",
      "walk_forward 50 0.9947862356621481\n",
      "walk_forward 100 0.9954814042405283\n",
      "walk_turn 10 0.9658119658119658\n",
      "walk_turn 20 0.9903846153846154\n",
      "walk_turn 25 0.9925213675213675\n",
      "walk_turn 50 0.9935897435897436\n",
      "walk_turn 100 0.9925213675213675\n",
      "run_forward 10 0.93756727664155\n",
      "run_forward 20 1.0\n",
      "run_forward 25 1.0\n",
      "run_forward 50 1.0\n",
      "run_forward 100 0.9989235737351991\n",
      "stationary 10 0.9848484848484849\n",
      "stationary 20 0.9873737373737373\n",
      "stationary 25 0.9848484848484849\n",
      "stationary 50 0.9848484848484849\n",
      "stationary 100 0.9848484848484849\n",
      "[[[1902    1    4    2   10    0]\n",
      "  [  18  626    0    0  243    0]\n",
      "  [   6    1 2788   70    3    9]\n",
      "  [   0    0   31  904    1    0]\n",
      "  [  13   43    2    0  871    0]\n",
      "  [   0    0    4    2    0  390]]\n",
      "\n",
      " [[1919    0    0    0    0    0]\n",
      "  [   0  794    0    0   93    0]\n",
      "  [   2    0 2859   14    2    0]\n",
      "  [   0    0    9  927    0    0]\n",
      "  [   0    0    0    0  929    0]\n",
      "  [   0    0    2    3    0  391]]\n",
      "\n",
      " [[1919    0    0    0    0    0]\n",
      "  [   0  848    0    0   39    0]\n",
      "  [   4    0 2864    8    1    0]\n",
      "  [   0    0    7  929    0    0]\n",
      "  [   0    0    0    0  929    0]\n",
      "  [   0    0    4    2    0  390]]\n",
      "\n",
      " [[1919    0    0    0    0    0]\n",
      "  [   0  866    0    0   21    0]\n",
      "  [   4    0 2862   10    1    0]\n",
      "  [   0    0    6  930    0    0]\n",
      "  [   0    0    0    0  929    0]\n",
      "  [   0    0    4    2    0  390]]\n",
      "\n",
      " [[1919    0    0    0    0    0]\n",
      "  [   0  880    0    0    7    0]\n",
      "  [   5    0 2864    7    1    0]\n",
      "  [   0    0    7  929    0    0]\n",
      "  [   1    0    0    0  928    0]\n",
      "  [   0    0    4    2    0  390]]]\n"
     ]
    }
   ],
   "source": [
    "# First step; IMU\n",
    "SR_GNSS_PRE = {  \n",
    "    LABEL['walk_forward']: 1,\n",
    "    LABEL['walk_turn']: 10,\n",
    "    LABEL['jog_forward']: 1,\n",
    "    LABEL['jog_turn']: 2,\n",
    "    LABEL['run_forward']: 2,\n",
    "    LABEL['stationary']: 1,\n",
    "}\n",
    "confusion_matrix = np.zeros([len(SR_IMU),6,6], dtype=int)\n",
    "\n",
    "# Calculate power, vRMSE, dRMSE\n",
    "har_acc = np.zeros([len(LABEL), len(SR_IMU)])\n",
    "power = np.zeros([len(LABEL), len(SR_GNSS)])\n",
    "vRMSE = np.zeros([len(LABEL), len(SR_GNSS)])\n",
    "dRMSE = np.zeros([len(LABEL), len(SR_GNSS)])\n",
    "pRMSE = np.zeros([len(LABEL), len(SR_GNSS)])\n",
    "\n",
    "for i, label in enumerate(LABEL):\n",
    "    images = train_images[label]\n",
    "    gnss = train_gnss[label]\n",
    "    for j, sr_imu in enumerate(SR_IMU):\n",
    "        for key in SR.keys():\n",
    "            SR[key][0] = SR_GNSS_PRE[key]\n",
    "            SR[key][1] = sr_imu\n",
    "        predictions = har_predict(images, SR[LABEL[label]][1])\n",
    "        har_acc[i,j] = get_accuracy(predictions, LABEL[label], confusion_matrix[j])\n",
    "        print(label, SR[LABEL[label]][1], har_acc[i,j])\n",
    "\n",
    "        for j, sr_gnss in enumerate(SR_GNSS):\n",
    "            for key in SR.keys():\n",
    "                SR[key][0] = sr_gnss\n",
    "            gnss_downsample = downsample(gnss, predictions)\n",
    "            gnss_interpolate = interpolate(gnss_downsample)\n",
    "            #print(sr_gnss, pd.DataFrame(gnss_interpolate[0].T,columns =  ['time','enu_x','enu_y','speed']))\n",
    "            power[i,j] = np.mean(calc_power(predictions))\n",
    "            dRMSE[i,j], pRMSE[i,j], vRMSE[i,j] = calc_error(gnss, gnss_interpolate)\n",
    "            \n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8870166666666668\n",
      "2.0469333333333335\n",
      "2.3028000000000004\n",
      "2.8465166666666666\n",
      "\n",
      "0.8722166666666666\n",
      "0.9461333333333334\n",
      "1.0644\n",
      "1.3157166666666666\n",
      "\n",
      "2.82905\n",
      "3.0687999999999995\n",
      "3.452400000000001\n",
      "4.26755\n",
      "\n",
      "0.9203999999999999\n",
      "0.9984000000000002\n",
      "1.1232\n",
      "1.3884\n",
      "\n",
      "0.9135166666666668\n",
      "0.9909333333333334\n",
      "1.1148000000000002\n",
      "1.3780166666666667\n",
      "\n",
      "0.3894\n",
      "0.42240000000000005\n",
      "0.47520000000000007\n",
      "0.5874\n",
      "\n",
      "===================================\n",
      "0.09811943026833496\n",
      "0.11476600784748249\n",
      "0.07866815187887052\n",
      "0.0\n",
      "\n",
      "0.19404385877970318\n",
      "0.10001652947266791\n",
      "0.07954517536583004\n",
      "0.0\n",
      "\n",
      "0.063366126015879\n",
      "0.06278562973371227\n",
      "0.04615088653365509\n",
      "0.0\n",
      "\n",
      "0.0399090130303915\n",
      "0.036330053932339984\n",
      "0.035078133417477245\n",
      "0.0\n",
      "\n",
      "0.17172816869506224\n",
      "0.10746033324919589\n",
      "0.08984498104491023\n",
      "0.0\n",
      "\n",
      "0.005619231585034596\n",
      "0.005388516123193509\n",
      "0.005186911208733544\n",
      "0.0\n",
      "\n",
      "===================================\n",
      "0.23175607801347917\n",
      "0.19274355979804053\n",
      "0.20662569070985565\n",
      "0.0\n",
      "\n",
      "0.31148858849090727\n",
      "0.18588190980297387\n",
      "0.19300315175969354\n",
      "0.0\n",
      "\n",
      "0.07372571396686588\n",
      "0.06576901127458916\n",
      "0.05086594940195247\n",
      "0.0\n",
      "\n",
      "0.07092375962285023\n",
      "0.05994731975361446\n",
      "0.049350309108218596\n",
      "0.0\n",
      "\n",
      "0.15122471779482452\n",
      "0.14085372309923647\n",
      "0.10749615758534982\n",
      "0.0\n",
      "\n",
      "0.0070214624196151\n",
      "0.005932410322274215\n",
      "0.00504833688777658\n",
      "0.0\n",
      "\n",
      "===================================\n",
      "0.07927714459194772\n",
      "0.08320895856220732\n",
      "0.0869850511206322\n",
      "0.0\n",
      "\n",
      "0.269290213733152\n",
      "0.10512261019370951\n",
      "0.098875907946862\n",
      "0.0\n",
      "\n",
      "0.04210549401510486\n",
      "0.04885786259945199\n",
      "0.03996659758348551\n",
      "0.0\n",
      "\n",
      "0.07522720509425994\n",
      "0.04717088144360089\n",
      "0.041746546202520926\n",
      "0.0\n",
      "\n",
      "0.10087968864214797\n",
      "0.08303637539056355\n",
      "0.07244552956027821\n",
      "0.0\n",
      "\n",
      "0.006205263888870146\n",
      "0.007341451175498669\n",
      "0.005796573781703291\n",
      "0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(power.shape[0]):\n",
    "    #print(get_key(i, LABEL))\n",
    "    for j in range(power.shape[1]):\n",
    "        print(power[i,j])\n",
    "    print()\n",
    "\n",
    "print(\"===================================\")\n",
    "for i in range(vRMSE.shape[0]):\n",
    "    #print(get_key(i, LABEL))\n",
    "    for j in range(vRMSE.shape[1]):\n",
    "        print(vRMSE[i,j])\n",
    "    print()\n",
    "    \n",
    "print(\"===================================\")\n",
    "for i in range(pRMSE.shape[0]):\n",
    "    #print(get_key(i, LABEL))\n",
    "    for j in range(pRMSE.shape[1]):\n",
    "        print(pRMSE[i,j])\n",
    "    print()\n",
    "    \n",
    "print(\"===================================\")\n",
    "for i in range(dRMSE.shape[0]):\n",
    "    #print(get_key(i, LABEL))\n",
    "    for j in range(dRMSE.shape[1]):\n",
    "        print(dRMSE[i,j])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(1, 1, 1, 1, 1, 1),\n",
       " (1, 2, 1, 1, 1, 1),\n",
       " (1, 2, 1, 1, 2, 1),\n",
       " (1, 2, 1, 1, 10, 1),\n",
       " (1, 2, 1, 2, 1, 1),\n",
       " (1, 2, 1, 2, 2, 1),\n",
       " (1, 10, 1, 1, 2, 1),\n",
       " (1, 10, 1, 1, 10, 1),\n",
       " (1, 10, 1, 2, 1, 1),\n",
       " (1, 10, 1, 2, 2, 1),\n",
       " (1, 10, 1, 2, 10, 1),\n",
       " (1, 10, 1, 10, 10, 1),\n",
       " (10, 10, 1, 1, 10, 1),\n",
       " (10, 10, 1, 2, 10, 1),\n",
       " (10, 10, 1, 10, 10, 1),\n",
       " (10, 10, 1, 10, 10, 10),\n",
       " (10, 10, 10, 10, 10, 1),\n",
       " (10, 10, 10, 10, 10, 10)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def worker(vRMSE,pRMSE,power,beta,proc_id,return_dict):\n",
    "    res = []\n",
    "    return_dict[proc_id] = []\n",
    "    #for alpha in np.linspace(0,1,num=10)\n",
    "    #print(proc_id)\n",
    "    #opt_gnss_sr = {key: 0 for key in LABEL}\n",
    "    f = lambda x: SR_GNSS[x]\n",
    "    for p, beta in enumerate(beta):\n",
    "        if(proc_id == 0):\n",
    "            print(p)\n",
    "        for alpha in np.linspace(0.0,1.0,num=10000):\n",
    "            G = alpha*power + (1-alpha)*((1-beta)*vRMSE+beta*dRMSE)\n",
    "        #G = alpha*power + (1-alpha)*((1-beta)*vRMSE+beta*pRMSE)\n",
    "\n",
    "            min_idx = np.argmin(G, axis=1)\n",
    "            opt_gnss_sr = tuple(np.fromiter([f(x) for x in min_idx], dtype=int))\n",
    "\n",
    "            if(opt_gnss_sr not in res):\n",
    "                res.append(opt_gnss_sr)\n",
    "\n",
    "         #   if(alpha >= 0.1):\n",
    "               # if(opt_gnss_sr in [(1,10,1,1,2,1),(1,10,1,1,10,1),(1,10,1,2,10,1)]):\n",
    "                #if(opt_gnss_sr in [(2,10,2,2,4,1)]):\n",
    "               #     print(\"{}\\t{:.5f}\\t{:.5f}\\t{}\".format(proc_id, beta, alpha, list(opt_gnss_sr)))\n",
    " #   print(f\"End {proc_id}\")\n",
    "    return_dict[proc_id] = res\n",
    "\n",
    "n_procs = 50\n",
    "betas = np.split(np.linspace(0.0,1.0,num=10000), n_procs)\n",
    "procs = []\n",
    "return_dict = mp.Manager().dict()\n",
    "for index, beta in enumerate(betas):\n",
    "    proc = mp.Process(target=worker, args=(vRMSE,pRMSE,power,beta,index,return_dict,))\n",
    "    #proc.daemon = True\n",
    "    procs.append(proc)\n",
    "    proc.start()\n",
    "        \n",
    "for p in procs:\n",
    "    p.join()\n",
    "vals = return_dict.values()\n",
    "keys = return_dict.keys()\n",
    "\n",
    "#a = routine(vRMSE,pRMSE,power,np.linspace(0.99,1.1,num=10),1)\n",
    "\n",
    "vals_new = []\n",
    "\n",
    "for items in vals:\n",
    "    for item in items:\n",
    "        vals_new.append(item)\n",
    "        \n",
    "vals_new = set(vals_new)\n",
    "vals_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
